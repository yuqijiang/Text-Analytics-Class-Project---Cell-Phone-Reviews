{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "\n",
    "# read data\n",
    "d = pd.read_csv('df_eng.csv', index_col = 0)\n",
    "product = list(d['phone_url'].str.split('/'))\n",
    "\n",
    "\n",
    "# parse brand and model from phont_url and add back to the dataframe\n",
    "product2 = []\n",
    "for i in product:\n",
    "    product2.append(i[2])\n",
    "    \n",
    "product2_split = []\n",
    "for p in product2:\n",
    "    product2_split.append(p.split('-'))\n",
    "\n",
    "brands = []\n",
    "for p in product2_split:\n",
    "    brands.append(p[0])\n",
    "    \n",
    "d['brand'] = brands\n",
    "\n",
    "models = []\n",
    "for p in product2_split:\n",
    "    models.append(p[1])\n",
    "    \n",
    "d['models'] = models\n",
    "\n",
    "\n",
    "# delete unused column\n",
    "del d['lang']\n",
    "del d['country']\n",
    "del d['domain']\n",
    "del d['score_max']\n",
    "del d['author']\n",
    "del d['product']\n",
    "\n",
    "\n",
    "# drop columns with nan score\n",
    "d.dropna(subset=['score'], inplace = True)\n",
    "d.dropna(subset = ['extract'], inplace = True)\n",
    "\n",
    "# lowercase extract text\n",
    "d['extract'] = d.apply(lambda row: str(row['extract']).lower(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>10.0</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>9.2</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date            source  score  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017  Verizon Wireless   10.0   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017       Phone Arena   10.0   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017            Amazon    6.0   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017           Samsung    9.2   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017  Verizon Wireless    4.0   \n",
       "\n",
       "                                             extract    brand  models  \n",
       "0  as a diehard samsung fan who has had every sam...  samsung  galaxy  \n",
       "1  love the phone. the phone is sleek and smooth ...  samsung  galaxy  \n",
       "2  adequate feel. nice heft. processor's still sl...  samsung  galaxy  \n",
       "3  never disappointed. one of the reasons i've be...  samsung  galaxy  \n",
       "4  i've now found that i'm in a group of people t...  samsung  galaxy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d.to_csv('data_cleaned.csv')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 100,000 data\n",
    "random.seed(1)\n",
    "d_sample = d.sample(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization and lemmatization function\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# make my own function that takes in a full sentence, tokenizes it, lemmatizes the words, then joins it back on white space\n",
    "# ref: taken from HW2 insturctor solution\n",
    "def lemmatize_sentence(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    res_words = []\n",
    "    for word in words:\n",
    "        res_words.append(lemmatizer.lemmatize(word).strip(string.punctuation))\n",
    "    return \" \".join(res_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['extract_str'] = d.apply(lambda row: str(row['extract']),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "      <th>extract_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>10.0</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>9.2</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date            source  score  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017  Verizon Wireless   10.0   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017       Phone Arena   10.0   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017            Amazon    6.0   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017           Samsung    9.2   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017  Verizon Wireless    4.0   \n",
       "\n",
       "                                             extract    brand  models  \\\n",
       "0  as a diehard samsung fan who has had every sam...  samsung  galaxy   \n",
       "1  love the phone. the phone is sleek and smooth ...  samsung  galaxy   \n",
       "2  adequate feel. nice heft. processor's still sl...  samsung  galaxy   \n",
       "3  never disappointed. one of the reasons i've be...  samsung  galaxy   \n",
       "4  i've now found that i'm in a group of people t...  samsung  galaxy   \n",
       "\n",
       "                                         extract_str  \n",
       "0  as a diehard samsung fan who has had every sam...  \n",
       "1  love the phone. the phone is sleek and smooth ...  \n",
       "2  adequate feel. nice heft. processor's still sl...  \n",
       "3  never disappointed. one of the reasons i've be...  \n",
       "4  i've now found that i'm in a group of people t...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "d['extract_lemma'] = d.apply(lambda row: lemmatize_sentence(row['extract_str']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "      <th>extract_str</th>\n",
       "      <th>extract_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>a a diehard samsung fan who ha had every samsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>10.0</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>love the phone  the phone is sleek and smooth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>adequate feel  nice heft  processor s still sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>9.2</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>never disappointed  one of the reason i ve bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>i ve now found that i m in a group of people t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date            source  score  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017  Verizon Wireless   10.0   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017       Phone Arena   10.0   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017            Amazon    6.0   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017           Samsung    9.2   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017  Verizon Wireless    4.0   \n",
       "\n",
       "                                             extract    brand  models  \\\n",
       "0  as a diehard samsung fan who has had every sam...  samsung  galaxy   \n",
       "1  love the phone. the phone is sleek and smooth ...  samsung  galaxy   \n",
       "2  adequate feel. nice heft. processor's still sl...  samsung  galaxy   \n",
       "3  never disappointed. one of the reasons i've be...  samsung  galaxy   \n",
       "4  i've now found that i'm in a group of people t...  samsung  galaxy   \n",
       "\n",
       "                                         extract_str  \\\n",
       "0  as a diehard samsung fan who has had every sam...   \n",
       "1  love the phone. the phone is sleek and smooth ...   \n",
       "2  adequate feel. nice heft. processor's still sl...   \n",
       "3  never disappointed. one of the reasons i've be...   \n",
       "4  i've now found that i'm in a group of people t...   \n",
       "\n",
       "                                       extract_lemma  \n",
       "0  a a diehard samsung fan who ha had every samsu...  \n",
       "1  love the phone  the phone is sleek and smooth ...  \n",
       "2  adequate feel  nice heft  processor s still sl...  \n",
       "3  never disappointed  one of the reason i ve bee...  \n",
       "4  i ve now found that i m in a group of people t...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization\n",
    "stopwords2 = stopwords.words() + ['phone', 'phones', 'cell', 'mobile'] # + brand ?\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2,4),\n",
    "                             token_pattern = r'\\b[a-zA-Z]{3,}\\b', # detect text with three or more alphanumeric words\n",
    "                             max_df = 0.4,\n",
    "                             min_df = 2,\n",
    "                             stop_words = stopwords2,\n",
    "                             max_features = 200 # keep top 200 features\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "      <th>extract_str</th>\n",
       "      <th>extract_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>a a diehard samsung fan who ha had every samsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>10.0</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>love the phone  the phone is sleek and smooth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>adequate feel  nice heft  processor s still sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>9.2</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>never disappointed  one of the reason i ve bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>i ve now found that i m in a group of people t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date            source  score  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017  Verizon Wireless   10.0   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017       Phone Arena   10.0   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017            Amazon    6.0   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017           Samsung    9.2   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017  Verizon Wireless    4.0   \n",
       "\n",
       "                                             extract    brand  models  \\\n",
       "0  as a diehard samsung fan who has had every sam...  samsung  galaxy   \n",
       "1  love the phone. the phone is sleek and smooth ...  samsung  galaxy   \n",
       "2  adequate feel. nice heft. processor's still sl...  samsung  galaxy   \n",
       "3  never disappointed. one of the reasons i've be...  samsung  galaxy   \n",
       "4  i've now found that i'm in a group of people t...  samsung  galaxy   \n",
       "\n",
       "                                         extract_str  \\\n",
       "0  as a diehard samsung fan who has had every sam...   \n",
       "1  love the phone. the phone is sleek and smooth ...   \n",
       "2  adequate feel. nice heft. processor's still sl...   \n",
       "3  never disappointed. one of the reasons i've be...   \n",
       "4  i've now found that i'm in a group of people t...   \n",
       "\n",
       "                                       extract_lemma  \n",
       "0  a a diehard samsung fan who ha had every samsu...  \n",
       "1  love the phone  the phone is sleek and smooth ...  \n",
       "2  adequate feel  nice heft  processor s still sl...  \n",
       "3  never disappointed  one of the reason i ve bee...  \n",
       "4  i ve now found that i m in a group of people t...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization\n",
    "corpus = list(d['extract_lemma'].values)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "features = X.toarray()\n",
    "d_formodel=pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "d_formodel['TARGET'] = d['score']  # adding target to the data frame\n",
    "d_formodel.index = d['extract'] # adding review to the data frame for future review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection and modeling - LASSO\n",
    "\n",
    "# split train, test sets\n",
    "train_df, test_df = train_test_split(d_formodel)\n",
    "\n",
    "X_train = train_df.loc[:, ~train_df.columns.isin(['TARGET'])] # remove target\n",
    "X_test = test_df.loc[:, ~test_df.columns.isin(['TARGET'])]\n",
    "\n",
    "y_train = train_df['TARGET'] # get target\n",
    "y_test = test_df['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.686609999999868"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline (mean)\n",
    "np.mean(d_sample['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.167074919068554"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline train RMSE\n",
    "baseline_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "baseline_rmse_train['predict'] = np.mean(d_sample['score'])\n",
    "baseline_rmse_train['rmse'] = (baseline_rmse_train['TARGET'] - baseline_rmse_train['predict']) ** 2\n",
    "(sum(baseline_rmse_train['rmse'])/ len(baseline_rmse_train)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "round(r2_score(y_true = baseline_rmse_train['TARGET'], y_pred = baseline_rmse_train['predict']), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.161516164824777"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline test RMSE\n",
    "baseline_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "baseline_rmse_test['predict'] = np.mean(d_sample['score'])\n",
    "baseline_rmse_test['rmse'] = (baseline_rmse_test['TARGET'] - baseline_rmse_test['predict']) ** 2\n",
    "(sum(baseline_rmse_test['rmse'])/ len(baseline_rmse_test)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "round(r2_score(y_true = baseline_rmse_test['TARGET'], y_pred = baseline_rmse_test['predict']), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression with alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso picked 30 variables and eliminated the other 170 variables\n"
     ]
    }
   ],
   "source": [
    "# LASSO model with alpha = 0.005\n",
    "# fit model to train\n",
    "reg = Lasso(alpha = 0.005) \n",
    "reg.fit(X_train, y_train)\n",
    "coef_lasso = pd.Series(reg.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef_lasso != 0)) + \" variables and eliminated the other \" +  str(sum(coef_lasso == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8547809058075946"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for train set\n",
    "y_pred = reg.predict(X_train)\n",
    "\n",
    "lasso_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "lasso_rmse_train['predict'] = y_pred\n",
    "lasso_rmse_train['rmse'] = (lasso_rmse_train['TARGET'] - lasso_rmse_train['predict']) ** 2\n",
    "(sum(lasso_rmse_train['rmse'])/ len(lasso_rmse_train)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07494222595829647"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_score(y_true = lasso_rmse_train['TARGET'], y_pred = lasso_rmse_train['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.844003060576442"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for test set\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "lasso_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "lasso_rmse_test['predict'] = y_pred\n",
    "lasso_rmse_test['rmse'] = (lasso_rmse_test['TARGET'] - lasso_rmse_test['predict']) ** 2\n",
    "(sum(lasso_rmse_test['rmse'])/ len(lasso_rmse_test)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07629195198275218"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set R2\n",
    "r2_score(y_true = lasso_rmse_test['TARGET'], y_pred = lasso_rmse_test['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression Cross Validation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso picked 197 variables and eliminated the other 3 variables\n"
     ]
    }
   ],
   "source": [
    "# LASSO CV model\n",
    "# fit model to train\n",
    "reg_cv = LassoCV()\n",
    "reg_cv.fit(X_train, y_train)\n",
    "coef_regcv = pd.Series(reg_cv.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef_regcv != 0)) + \" variables and eliminated the other \" +  str(sum(coef_regcv == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5904381447044953"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for train set\n",
    "y_pred = reg_cv.predict(X_train)\n",
    "\n",
    "lassocv_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "lassocv_rmse_train['predict'] = y_pred\n",
    "lassocv_rmse_train['rmse'] = (lassocv_rmse_train['TARGET'] - lassocv_rmse_train['predict']) ** 2\n",
    "(sum(lassocv_rmse_train['rmse'])/ len(lassocv_rmse_train)) ** 1/2   # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13837834130742577"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_score(y_true = lassocv_rmse_train['TARGET'], y_pred = lassocv_rmse_train['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.573596055865725"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for test set\n",
    "y_pred = reg_cv.predict(X_test)\n",
    "\n",
    "lassocv_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "lassocv_rmse_test['predict'] = y_pred\n",
    "lassocv_rmse_test['rmse'] = (lassocv_rmse_test['TARGET'] - lassocv_rmse_test['predict']) ** 2\n",
    "(sum(lassocv_rmse_test['rmse'])/ len(lassocv_rmse_test)) ** 1/2   # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14127034106081493"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_score(y_true = lassocv_rmse_test['TARGET'], y_pred = lassocv_rmse_test['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients of Best Model (LASSO CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent product    2.402269\n",
       "best ever            2.266377\n",
       "best smartphone      2.255996\n",
       "absolutely love      2.197169\n",
       "love new             2.166301\n",
       "work perfectly       2.123162\n",
       "highly recommend     2.116530\n",
       "love love            2.115676\n",
       "great product        2.083842\n",
       "far best             2.060095\n",
       "super fast           1.966025\n",
       "best price           1.936327\n",
       "great love           1.936180\n",
       "love everything      1.903395\n",
       "easy set             1.870449\n",
       "one best             1.867354\n",
       "work great           1.829445\n",
       "happy purchase       1.792538\n",
       "really love          1.782445\n",
       "doe everything       1.776124\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most negative mentioned\n",
    "coef_regcv_desc = coef_regcv.sort_values(ascending = False)\n",
    "coef_regcv_desc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst ever         -5.699143\n",
       "waste money        -4.858022\n",
       "dont buy           -4.600128\n",
       "stopped working    -3.999490\n",
       "doe work           -3.617142\n",
       "working properly   -3.438906\n",
       "hold charge        -2.488924\n",
       "battery drain      -2.147692\n",
       "every time         -2.118779\n",
       "two month          -1.889037\n",
       "one month          -1.867226\n",
       "heating problem    -1.682193\n",
       "battery doe        -1.596176\n",
       "could get          -1.441465\n",
       "make call          -1.396745\n",
       "text message       -1.365618\n",
       "many time          -1.330714\n",
       "one day            -1.214200\n",
       "sim card           -1.072702\n",
       "two week           -1.034376\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most positive mentioned\n",
    "coef_regcv_asc = coef_regcv.sort_values()\n",
    "coef_regcv_asc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
