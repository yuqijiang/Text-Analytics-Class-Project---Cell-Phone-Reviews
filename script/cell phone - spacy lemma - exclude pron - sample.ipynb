{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "\n",
    "# read data\n",
    "d = pd.read_csv('df_eng.csv', index_col = 0)\n",
    "product = list(d['phone_url'].str.split('/'))\n",
    "\n",
    "\n",
    "# parse brand and model from phont_url and add back to the dataframe\n",
    "product2 = []\n",
    "for i in product:\n",
    "    product2.append(i[2])\n",
    "    \n",
    "product2_split = []\n",
    "for p in product2:\n",
    "    product2_split.append(p.split('-'))\n",
    "\n",
    "brands = []\n",
    "for p in product2_split:\n",
    "    brands.append(p[0])\n",
    "    \n",
    "d['brand'] = brands\n",
    "\n",
    "models = []\n",
    "for p in product2_split:\n",
    "    models.append(p[1])\n",
    "    \n",
    "d['models'] = models\n",
    "\n",
    "\n",
    "# delete unused column\n",
    "del d['lang']\n",
    "del d['country']\n",
    "del d['domain']\n",
    "del d['score_max']\n",
    "del d['author']\n",
    "del d['product']\n",
    "\n",
    "\n",
    "# drop columns with nan score\n",
    "d.dropna(subset=['score'], inplace = True)\n",
    "d.dropna(subset = ['extract'], inplace = True)\n",
    "\n",
    "# lowercase extract text\n",
    "d['extract'] = d.apply(lambda row: str(row['extract']).lower(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>10.0</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>9.2</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date            source  score  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017  Verizon Wireless   10.0   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017       Phone Arena   10.0   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017            Amazon    6.0   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017           Samsung    9.2   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017  Verizon Wireless    4.0   \n",
       "\n",
       "                                             extract    brand  models  \n",
       "0  as a diehard samsung fan who has had every sam...  samsung  galaxy  \n",
       "1  love the phone. the phone is sleek and smooth ...  samsung  galaxy  \n",
       "2  adequate feel. nice heft. processor's still sl...  samsung  galaxy  \n",
       "3  never disappointed. one of the reasons i've be...  samsung  galaxy  \n",
       "4  i've now found that i'm in a group of people t...  samsung  galaxy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d.to_csv('data_cleaned.csv')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 100,000 reviews\n",
    "random.seed(1)\n",
    "d = d.sample(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization and lemmatization function\n",
    "def token_lemma(df,col):\n",
    "    # tokenize by spacy\n",
    "    nlp = spacy.load('en')\n",
    "    df['token'] = df[col].apply(lambda x: nlp(x))\n",
    "    # lemmatize by spacy\n",
    "    df['lemmatized'] = df['token'].apply(lambda x: \" \".join([token.lemma_ if token.lemma_ != \"-PRON-\" else token.text for token in x]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['extract_str'] = d.apply(lambda row: str(row['extract']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "      <th>extract_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>648897</th>\n",
       "      <td>/cellphones/apple-iphone-5s/</td>\n",
       "      <td>1/3/2014</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nonsense wicked people</td>\n",
       "      <td>apple</td>\n",
       "      <td>iphone</td>\n",
       "      <td>nonsense wicked people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474804</th>\n",
       "      <td>/cellphones/motorola-razr-v3/</td>\n",
       "      <td>6/23/2013</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>this order was a huge mistake. would have veri...</td>\n",
       "      <td>motorola</td>\n",
       "      <td>razr</td>\n",
       "      <td>this order was a huge mistake. would have veri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080685</th>\n",
       "      <td>/cellphones/nokia-asha-300/</td>\n",
       "      <td>6/6/2012</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>it works well, is simple to use, especially if...</td>\n",
       "      <td>nokia</td>\n",
       "      <td>asha</td>\n",
       "      <td>it works well, is simple to use, especially if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626988</th>\n",
       "      <td>/cellphones/lenovo-vibe-k5/</td>\n",
       "      <td>7/13/2016</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>phone works with full satisfaction including o...</td>\n",
       "      <td>lenovo</td>\n",
       "      <td>vibe</td>\n",
       "      <td>phone works with full satisfaction including o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13546</th>\n",
       "      <td>/cellphones/samsung-galaxy-s7-edge/</td>\n",
       "      <td>3/26/2016</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>10.0</td>\n",
       "      <td>the galaxy s7 edge is by far the best phone i ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>the galaxy s7 edge is by far the best phone i ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   phone_url       date   source  score  \\\n",
       "648897          /cellphones/apple-iphone-5s/   1/3/2014   Amazon    2.0   \n",
       "1474804        /cellphones/motorola-razr-v3/  6/23/2013   Amazon    2.0   \n",
       "1080685          /cellphones/nokia-asha-300/   6/6/2012   Amazon   10.0   \n",
       "626988           /cellphones/lenovo-vibe-k5/  7/13/2016   Amazon   10.0   \n",
       "13546    /cellphones/samsung-galaxy-s7-edge/  3/26/2016  Samsung   10.0   \n",
       "\n",
       "                                                   extract     brand  models  \\\n",
       "648897                              nonsense wicked people     apple  iphone   \n",
       "1474804  this order was a huge mistake. would have veri...  motorola    razr   \n",
       "1080685  it works well, is simple to use, especially if...     nokia    asha   \n",
       "626988   phone works with full satisfaction including o...    lenovo    vibe   \n",
       "13546    the galaxy s7 edge is by far the best phone i ...   samsung  galaxy   \n",
       "\n",
       "                                               extract_str  \n",
       "648897                              nonsense wicked people  \n",
       "1474804  this order was a huge mistake. would have veri...  \n",
       "1080685  it works well, is simple to use, especially if...  \n",
       "626988   phone works with full satisfaction including o...  \n",
       "13546    the galaxy s7 edge is by far the best phone i ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "d_lemma = token_lemma(d, 'extract_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "      <th>extract_str</th>\n",
       "      <th>token</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>648897</th>\n",
       "      <td>/cellphones/apple-iphone-5s/</td>\n",
       "      <td>1/3/2014</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nonsense wicked people</td>\n",
       "      <td>apple</td>\n",
       "      <td>iphone</td>\n",
       "      <td>nonsense wicked people</td>\n",
       "      <td>(nonsense, wicked, people)</td>\n",
       "      <td>nonsense wicked people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474804</th>\n",
       "      <td>/cellphones/motorola-razr-v3/</td>\n",
       "      <td>6/23/2013</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>this order was a huge mistake. would have veri...</td>\n",
       "      <td>motorola</td>\n",
       "      <td>razr</td>\n",
       "      <td>this order was a huge mistake. would have veri...</td>\n",
       "      <td>(this, order, was, a, huge, mistake, ., would,...</td>\n",
       "      <td>this order be a huge mistake . would have veri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080685</th>\n",
       "      <td>/cellphones/nokia-asha-300/</td>\n",
       "      <td>6/6/2012</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>it works well, is simple to use, especially if...</td>\n",
       "      <td>nokia</td>\n",
       "      <td>asha</td>\n",
       "      <td>it works well, is simple to use, especially if...</td>\n",
       "      <td>(it, works, well, ,, is, simple, to, use, ,, e...</td>\n",
       "      <td>it work well , be simple to use , especially i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626988</th>\n",
       "      <td>/cellphones/lenovo-vibe-k5/</td>\n",
       "      <td>7/13/2016</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>phone works with full satisfaction including o...</td>\n",
       "      <td>lenovo</td>\n",
       "      <td>vibe</td>\n",
       "      <td>phone works with full satisfaction including o...</td>\n",
       "      <td>(phone, works, with, full, satisfaction, inclu...</td>\n",
       "      <td>phone work with full satisfaction include otg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13546</th>\n",
       "      <td>/cellphones/samsung-galaxy-s7-edge/</td>\n",
       "      <td>3/26/2016</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>10.0</td>\n",
       "      <td>the galaxy s7 edge is by far the best phone i ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>the galaxy s7 edge is by far the best phone i ...</td>\n",
       "      <td>(the, galaxy, s7, edge, is, by, far, the, best...</td>\n",
       "      <td>the galaxy s7 edge be by far the good phone i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288404</th>\n",
       "      <td>/cellphones/samsung-galaxy-note-4/</td>\n",
       "      <td>12/15/2014</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>8.0</td>\n",
       "      <td>i would have given this 5 stars if it had arri...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>i would have given this 5 stars if it had arri...</td>\n",
       "      <td>(i, would, have, given, this, 5, stars, if, it...</td>\n",
       "      <td>i would have give this 5 star if it have arriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498840</th>\n",
       "      <td>/cellphones/nokia-3100/</td>\n",
       "      <td>10/23/2004</td>\n",
       "      <td>Phone Scoop</td>\n",
       "      <td>9.0</td>\n",
       "      <td>i've had this phone for about three weeks now,...</td>\n",
       "      <td>nokia</td>\n",
       "      <td>3100</td>\n",
       "      <td>i've had this phone for about three weeks now,...</td>\n",
       "      <td>(i, 've, had, this, phone, for, about, three, ...</td>\n",
       "      <td>i have have this phone for about three week no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552011</th>\n",
       "      <td>/cellphones/lg-g2-594708/</td>\n",
       "      <td>12/4/2013</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>8.0</td>\n",
       "      <td>recieved on a time line and very happy with th...</td>\n",
       "      <td>lg</td>\n",
       "      <td>g2</td>\n",
       "      <td>recieved on a time line and very happy with th...</td>\n",
       "      <td>(recieved, on, a, time, line, and, very, happy...</td>\n",
       "      <td>reciev on a time line and very happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518083</th>\n",
       "      <td>/cellphones/audiovox-cdm-9155gpx-cdm9155sp/</td>\n",
       "      <td>6/23/2004</td>\n",
       "      <td>Phone Scoop</td>\n",
       "      <td>8.0</td>\n",
       "      <td>i used this phone for the past two years, and ...</td>\n",
       "      <td>audiovox</td>\n",
       "      <td>cdm</td>\n",
       "      <td>i used this phone for the past two years, and ...</td>\n",
       "      <td>(i, used, this, phone, for, the, past, two, ye...</td>\n",
       "      <td>i use this phone for the past two year , and m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387150</th>\n",
       "      <td>/cellphones/samsung-galaxy-j1/</td>\n",
       "      <td>10/22/2015</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>this phone has been great. i've had it for mor...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>this phone has been great. i've had it for mor...</td>\n",
       "      <td>(this, phone, has, been, great, ., i, 've, had...</td>\n",
       "      <td>this phone have be great . i have have it for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           phone_url        date       source  \\\n",
       "648897                  /cellphones/apple-iphone-5s/    1/3/2014       Amazon   \n",
       "1474804                /cellphones/motorola-razr-v3/   6/23/2013       Amazon   \n",
       "1080685                  /cellphones/nokia-asha-300/    6/6/2012       Amazon   \n",
       "626988                   /cellphones/lenovo-vibe-k5/   7/13/2016       Amazon   \n",
       "13546            /cellphones/samsung-galaxy-s7-edge/   3/26/2016      Samsung   \n",
       "288404            /cellphones/samsung-galaxy-note-4/  12/15/2014       Amazon   \n",
       "1498840                      /cellphones/nokia-3100/  10/23/2004  Phone Scoop   \n",
       "552011                     /cellphones/lg-g2-594708/   12/4/2013       Amazon   \n",
       "1518083  /cellphones/audiovox-cdm-9155gpx-cdm9155sp/   6/23/2004  Phone Scoop   \n",
       "387150                /cellphones/samsung-galaxy-j1/  10/22/2015       Amazon   \n",
       "\n",
       "         score                                            extract     brand  \\\n",
       "648897     2.0                             nonsense wicked people     apple   \n",
       "1474804    2.0  this order was a huge mistake. would have veri...  motorola   \n",
       "1080685   10.0  it works well, is simple to use, especially if...     nokia   \n",
       "626988    10.0  phone works with full satisfaction including o...    lenovo   \n",
       "13546     10.0  the galaxy s7 edge is by far the best phone i ...   samsung   \n",
       "288404     8.0  i would have given this 5 stars if it had arri...   samsung   \n",
       "1498840    9.0  i've had this phone for about three weeks now,...     nokia   \n",
       "552011     8.0  recieved on a time line and very happy with th...        lg   \n",
       "1518083    8.0  i used this phone for the past two years, and ...  audiovox   \n",
       "387150    10.0  this phone has been great. i've had it for mor...   samsung   \n",
       "\n",
       "         models                                        extract_str  \\\n",
       "648897   iphone                             nonsense wicked people   \n",
       "1474804    razr  this order was a huge mistake. would have veri...   \n",
       "1080685    asha  it works well, is simple to use, especially if...   \n",
       "626988     vibe  phone works with full satisfaction including o...   \n",
       "13546    galaxy  the galaxy s7 edge is by far the best phone i ...   \n",
       "288404   galaxy  i would have given this 5 stars if it had arri...   \n",
       "1498840    3100  i've had this phone for about three weeks now,...   \n",
       "552011       g2  recieved on a time line and very happy with th...   \n",
       "1518083     cdm  i used this phone for the past two years, and ...   \n",
       "387150   galaxy  this phone has been great. i've had it for mor...   \n",
       "\n",
       "                                                     token  \\\n",
       "648897                          (nonsense, wicked, people)   \n",
       "1474804  (this, order, was, a, huge, mistake, ., would,...   \n",
       "1080685  (it, works, well, ,, is, simple, to, use, ,, e...   \n",
       "626988   (phone, works, with, full, satisfaction, inclu...   \n",
       "13546    (the, galaxy, s7, edge, is, by, far, the, best...   \n",
       "288404   (i, would, have, given, this, 5, stars, if, it...   \n",
       "1498840  (i, 've, had, this, phone, for, about, three, ...   \n",
       "552011   (recieved, on, a, time, line, and, very, happy...   \n",
       "1518083  (i, used, this, phone, for, the, past, two, ye...   \n",
       "387150   (this, phone, has, been, great, ., i, 've, had...   \n",
       "\n",
       "                                                lemmatized  \n",
       "648897                              nonsense wicked people  \n",
       "1474804  this order be a huge mistake . would have veri...  \n",
       "1080685  it work well , be simple to use , especially i...  \n",
       "626988   phone work with full satisfaction include otg ...  \n",
       "13546    the galaxy s7 edge be by far the good phone i ...  \n",
       "288404   i would have give this 5 star if it have arriv...  \n",
       "1498840  i have have this phone for about three week no...  \n",
       "552011   reciev on a time line and very happy with the ...  \n",
       "1518083  i use this phone for the past two year , and m...  \n",
       "387150   this phone have be great . i have have it for ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_lemma.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization\n",
    "stopwords2 = stopwords.words() + ['phone', 'phones', 'cell', 'mobile']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2, 3),\n",
    "                             token_pattern = r'\\b[a-zA-Z]{3,}\\b', # detect text with three or more alphanumeric words\n",
    "                             max_df = 0.4,\n",
    "                             min_df = 2,\n",
    "                             stop_words = stopwords2,\n",
    "                             max_features = 200 # keep top 200 features\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_lemma2 = d_lemma.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'printr', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# vectorization\n",
    "corpus = list(d_lemma2[\"lemmatized\"].values)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "features = X.toarray()\n",
    "d_formodel=pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "d_formodel['TARGET'] = d_lemma2['score']  # adding target to the data frame\n",
    "d_formodel.index = d_lemma2['extract'] # adding review to the data frame for future review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection and modeling - LASSO\n",
    "\n",
    "# split train, test sets\n",
    "train_df, test_df = train_test_split(d_formodel)\n",
    "\n",
    "X_train = train_df.loc[:, ~train_df.columns.isin(['TARGET'])] # remove target\n",
    "X_test = test_df.loc[:, ~test_df.columns.isin(['TARGET'])]\n",
    "\n",
    "y_train = train_df['TARGET'] # get target\n",
    "y_test = test_df['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.681789999999892"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline (mean)\n",
    "np.mean(d['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1855039474188525"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline train RMSE\n",
    "baseline_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "baseline_rmse_train['predict'] = np.mean(d['score'])\n",
    "baseline_rmse_train['rmse'] = (baseline_rmse_train['TARGET'] - baseline_rmse_train['predict']) ** 2\n",
    "(sum(baseline_rmse_train['rmse'])/ len(baseline_rmse_train)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "round(r2_score(y_true = baseline_rmse_train['TARGET'], y_pred = baseline_rmse_train['predict']), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.132450149530471"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline test RMSE\n",
    "baseline_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "baseline_rmse_test['predict'] = np.mean(d['score'])\n",
    "baseline_rmse_test['rmse'] = (baseline_rmse_test['TARGET'] - baseline_rmse_test['predict']) ** 2\n",
    "(sum(baseline_rmse_test['rmse'])/ len(baseline_rmse_test)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "round(r2_score(y_true = baseline_rmse_test['TARGET'], y_pred = baseline_rmse_test['predict']), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression \n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "coef_lr = pd.Series(lr.coef_, index = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5751940749143327"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for train set\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "linear_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "linear_rmse_train['predict'] = y_pred\n",
    "linear_rmse_train['rmse'] = (linear_rmse_train['TARGET'] - linear_rmse_train['predict']) ** 2\n",
    "(sum(linear_rmse_train['rmse'])/ len(linear_rmse_train)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14581505803425288"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_lr_train = r2_score(y_true = linear_rmse_train['TARGET'], y_pred = linear_rmse_train['predict'])\n",
    "r2_lr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973961034799764"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set adj R2\n",
    "adj_r2_lr_train = 1 - (1 - r2_lr_train ** 2) * ((X_train.shape[1] - 1) / (X_train.shape[0] - X_train.shape[1] - 1))\n",
    "adj_r2_lr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5518722078156406"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "linear_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "linear_rmse_test['predict'] = y_pred\n",
    "linear_rmse_test['rmse'] = (linear_rmse_test['TARGET'] - linear_rmse_test['predict']) ** 2\n",
    "(sum(linear_rmse_test['rmse'])/ len(linear_rmse_test)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1404916106051738"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set R2\n",
    "r2_lr_test = r2_score(y_true = linear_rmse_test['TARGET'], y_pred = linear_rmse_test['predict'])\n",
    "r2_lr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973920485653209"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set adj R2\n",
    "adj_r2_lr_test = 1 - (1 - r2_lr_test ** 2) * ((X_train.shape[1] - 1) / (X_train.shape[0] - X_train.shape[1] - 1))\n",
    "adj_r2_lr_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression with alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso picked 150 variables and eliminated the other 50 variables\n"
     ]
    }
   ],
   "source": [
    "# LASSO model with alpha = 0.005\n",
    "# fit model to train\n",
    "reg = Lasso(alpha = 0.001) \n",
    "reg.fit(X_train, y_train)\n",
    "coef_lasso = pd.Series(reg.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef_lasso != 0)) + \" variables and eliminated the other \" +  str(sum(coef_lasso == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6099357773052203"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for train set\n",
    "y_pred = reg.predict(X_train)\n",
    "\n",
    "lasso_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "lasso_rmse_train['predict'] = y_pred\n",
    "lasso_rmse_train['rmse'] = (lasso_rmse_train['TARGET'] - lasso_rmse_train['predict']) ** 2\n",
    "(sum(lasso_rmse_train['rmse'])/ len(lasso_rmse_train)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13751457464265082"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_reg_train = r2_score(y_true = lasso_rmse_train['TARGET'], y_pred = lasso_rmse_train['predict'])\n",
    "r2_reg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973898466742817"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set adj R2\n",
    "adj_r2_reg_train = 1 - (1 - r2_reg_train ** 2) * ((X_train.shape[1] - 1) / (X_train.shape[0] - X_train.shape[1] - 1))\n",
    "adj_r2_reg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5754581894215813"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for test set\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "lasso_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "lasso_rmse_test['predict'] = y_pred\n",
    "lasso_rmse_test['rmse'] = (lasso_rmse_test['TARGET'] - lasso_rmse_test['predict']) ** 2\n",
    "(sum(lasso_rmse_test['rmse'])/ len(lasso_rmse_test)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13478409978381423"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set R2\n",
    "r2_reg_test = r2_score(y_true = lasso_rmse_test['TARGET'], y_pred = lasso_rmse_test['predict'])\n",
    "r2_reg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973878686072989"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set adj R2\n",
    "adj_r2_reg_test = 1 - (1 - r2_reg_test ** 2) * ((X_train.shape[1] - 1) / (X_train.shape[0] - X_train.shape[1] - 1))\n",
    "adj_r2_reg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression Cross Validation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso picked 198 variables and eliminated the other 2 variables\n"
     ]
    }
   ],
   "source": [
    "# LASSO CV model\n",
    "# fit model to train\n",
    "reg_cv = LassoCV(cv = 5)\n",
    "reg_cv.fit(X_train, y_train)\n",
    "coef_regcv = pd.Series(reg_cv.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef_regcv != 0)) + \" variables and eliminated the other \" +  str(sum(coef_regcv == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5753190200605016"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for train set\n",
    "y_pred = reg_cv.predict(X_train)\n",
    "\n",
    "lassocv_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "lassocv_rmse_train['predict'] = y_pred\n",
    "lassocv_rmse_train['rmse'] = (lassocv_rmse_train['TARGET'] - lassocv_rmse_train['predict']) ** 2\n",
    "(sum(lassocv_rmse_train['rmse'])/ len(lassocv_rmse_train)) ** 1/2   # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1457852061545145"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_regcv_train = r2_score(y_true = lassocv_rmse_train['TARGET'], y_pred = lassocv_rmse_train['predict'])\n",
    "r2_regcv_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973960803211323"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set adj R2\n",
    "adj_r2_regcv_train = 1 - (1 - r2_regcv_train ** 2) * ((X_train.shape[1] - 1) / (X_train.shape[0] - X_train.shape[1] - 1))\n",
    "adj_r2_regcv_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5513581652835553"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for test set\n",
    "y_pred = reg_cv.predict(X_test)\n",
    "\n",
    "lassocv_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "lassocv_rmse_test['predict'] = y_pred\n",
    "lassocv_rmse_test['rmse'] = (lassocv_rmse_test['TARGET'] - lassocv_rmse_test['predict']) ** 2\n",
    "(sum(lassocv_rmse_test['rmse'])/ len(lassocv_rmse_test)) ** 1/2   # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14061600243096084"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set R2\n",
    "r2_regcv_test = r2_score(y_true = lassocv_rmse_test['TARGET'], y_pred = lassocv_rmse_test['predict'])\n",
    "r2_regcv_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973921415950453"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set adj R2\n",
    "adj_r2_regcv_test = 1 - (1 - r2_regcv_test ** 2) * ((X_train.shape[1] - 1) / (X_train.shape[0] - X_train.shape[1] - 1))\n",
    "adj_r2_regcv_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients of Best Model (LASSO CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad ever            -5.572641\n",
       "waste money         -4.850061\n",
       "stop work           -4.207888\n",
       "work properly       -3.737942\n",
       "send back           -3.647684\n",
       "two month           -2.430124\n",
       "battery drain       -2.374894\n",
       "month use           -2.143992\n",
       "get hot             -2.079389\n",
       "drop call           -1.953762\n",
       "could get           -1.852234\n",
       "heating problem     -1.828147\n",
       "one month           -1.780048\n",
       "could use           -1.626493\n",
       "one day             -1.524536\n",
       "buy new             -1.428890\n",
       "make call           -1.329083\n",
       "text message        -1.140568\n",
       "buy another         -1.131613\n",
       "sim card            -1.075697\n",
       "time get            -1.047834\n",
       "back cover          -0.982143\n",
       "look like           -0.879413\n",
       "last month          -0.829493\n",
       "two week            -0.815823\n",
       "internal memory     -0.811672\n",
       "first get           -0.716438\n",
       "first time          -0.709179\n",
       "month ago           -0.662787\n",
       "give star           -0.648772\n",
       "one year            -0.618881\n",
       "touch screen        -0.609667\n",
       "day use             -0.580879\n",
       "get new             -0.517695\n",
       "heating issue       -0.480028\n",
       "straight talk       -0.401636\n",
       "even though         -0.386777\n",
       "new one             -0.373810\n",
       "memory card         -0.279732\n",
       "front camera        -0.191813\n",
       "camera quality      -0.168767\n",
       "good value money    -0.159124\n",
       "battery back        -0.102394\n",
       "last long           -0.097387\n",
       "battery good        -0.069916\n",
       "would buy           -0.039700\n",
       "would like          -0.030385\n",
       "sound quality       -0.030252\n",
       "battery life good    0.000000\n",
       "battery backup       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most negative mentioned\n",
    "coef_regcv_asc = coef_regcv.sort_values()\n",
    "coef_regcv_asc[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent product    2.393180\n",
       "good ever            2.314092\n",
       "love new             2.247280\n",
       "highly recommend     2.087740\n",
       "absolutely love      2.071476\n",
       "great product        2.050072\n",
       "love love            2.044664\n",
       "everything need      1.995682\n",
       "super fast           1.993144\n",
       "good smartphone      1.951325\n",
       "good iphone          1.942708\n",
       "work perfectly       1.939957\n",
       "great love           1.909319\n",
       "love everything      1.906491\n",
       "easy set             1.905297\n",
       "happy purchase       1.898938\n",
       "great price          1.859615\n",
       "great buy            1.850995\n",
       "easy use             1.794416\n",
       "great value          1.757412\n",
       "work great           1.737793\n",
       "love samsung         1.717580\n",
       "galaxy edge          1.636879\n",
       "large screen         1.623331\n",
       "far good             1.619593\n",
       "one good             1.583589\n",
       "value money          1.578040\n",
       "nice product         1.577375\n",
       "light weight         1.567261\n",
       "good android         1.561473\n",
       "big screen           1.557646\n",
       "really love          1.510675\n",
       "great good           1.509624\n",
       "great feature        1.480733\n",
       "like much            1.449978\n",
       "good price           1.427908\n",
       "good product         1.400619\n",
       "everything work      1.396832\n",
       "really good          1.387061\n",
       "many feature         1.353854\n",
       "great camera         1.352259\n",
       "good value           1.337991\n",
       "work like            1.322675\n",
       "must say             1.322392\n",
       "great great          1.314070\n",
       "high quality         1.289609\n",
       "great screen         1.269268\n",
       "long battery         1.267645\n",
       "get use              1.253603\n",
       "really nice          1.247700\n",
       "dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most positive mentioned\n",
    "coef_regcv_desc = coef_regcv.sort_values(ascending = False)\n",
    "coef_regcv_desc[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Real Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'printr', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# test reviews data processing\n",
    "test = pd.read_excel('test_review.xlsx', sheet_name = 'Sheet1')\n",
    "test['review'] = test.apply(lambda row: str(row['review']).lower(),axis=1)\n",
    "test['review_str'] = test.apply(lambda row: str(row['review']),axis=1)\n",
    "\n",
    "test_lemma = token_lemma(test, 'review_str')\n",
    "\n",
    "stopwords2 = stopwords.words() + ['phone', 'phones', 'cell', 'mobile']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2, 3),\n",
    "                             token_pattern = r'\\b[a-zA-Z]{3,}\\b', # detect text with three or more alphanumeric words\n",
    "                             stop_words = stopwords2,\n",
    "                             max_features = 200 # keep top 200 features\n",
    "                            )\n",
    "\n",
    "test_lemma2 = test_lemma.reset_index(drop = True)\n",
    "\n",
    "# vectorization\n",
    "corpus = list(test_lemma2[\"lemmatized\"].values)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "features = X.toarray()\n",
    "test_formodel=pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "test_formodel['TARGET'] = test_lemma2['rating']  # adding target to the data frame\n",
    "test_formodel.index = test_lemma2['review'] # adding review to the data frame for future review\n",
    "\n",
    "testset = test_formodel.loc[:, ~test_formodel.columns.isin(['TARGET'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.96857064, 11.38131819,  8.3729117 ,  9.96626309,  9.3764885 ,\n",
       "        8.4553915 ,  8.93655013,  7.13312804,  7.22749158,  7.72250885,\n",
       "        2.59014717,  9.57218264,  9.13964042])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = reg_cv.predict(testset)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.3764885 , 2.59014717])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict select reivews scores\n",
    "review1 = pd.DataFrame(testset.iloc[4,]).T\n",
    "review2 = pd.DataFrame(testset.iloc[10,]).T\n",
    "testset = review1.append(review2)\n",
    "test_pred = reg_cv.predict(testset)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
