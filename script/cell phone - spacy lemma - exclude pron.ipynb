{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "\n",
    "# read data\n",
    "d = pd.read_csv('df_eng.csv', index_col = 0)\n",
    "product = list(d['phone_url'].str.split('/'))\n",
    "\n",
    "\n",
    "# parse brand and model from phont_url and add back to the dataframe\n",
    "product2 = []\n",
    "for i in product:\n",
    "    product2.append(i[2])\n",
    "    \n",
    "product2_split = []\n",
    "for p in product2:\n",
    "    product2_split.append(p.split('-'))\n",
    "\n",
    "brands = []\n",
    "for p in product2_split:\n",
    "    brands.append(p[0])\n",
    "    \n",
    "d['brand'] = brands\n",
    "\n",
    "models = []\n",
    "for p in product2_split:\n",
    "    models.append(p[1])\n",
    "    \n",
    "d['models'] = models\n",
    "\n",
    "\n",
    "# delete unused column\n",
    "del d['lang']\n",
    "del d['country']\n",
    "del d['domain']\n",
    "del d['score_max']\n",
    "del d['author']\n",
    "del d['product']\n",
    "\n",
    "\n",
    "# drop columns with nan score\n",
    "d.dropna(subset=['score'], inplace = True)\n",
    "d.dropna(subset = ['extract'], inplace = True)\n",
    "\n",
    "# lowercase extract text\n",
    "d['extract'] = d.apply(lambda row: str(row['extract']).lower(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>10.0</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>9.2</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date            source  score  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017  Verizon Wireless   10.0   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017       Phone Arena   10.0   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017            Amazon    6.0   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017           Samsung    9.2   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017  Verizon Wireless    4.0   \n",
       "\n",
       "                                             extract    brand  models  \n",
       "0  as a diehard samsung fan who has had every sam...  samsung  galaxy  \n",
       "1  love the phone. the phone is sleek and smooth ...  samsung  galaxy  \n",
       "2  adequate feel. nice heft. processor's still sl...  samsung  galaxy  \n",
       "3  never disappointed. one of the reasons i've be...  samsung  galaxy  \n",
       "4  i've now found that i'm in a group of people t...  samsung  galaxy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d.to_csv('data_cleaned.csv')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization and lemmatization function\n",
    "def token_lemma(df,col):\n",
    "    # tokenize by spacy\n",
    "    nlp = spacy.load('en')\n",
    "    df['token'] = df[col].apply(lambda x: nlp(x))\n",
    "    # lemmatize by spacy\n",
    "    df['lemmatized'] = df['token'].apply(lambda x: \" \".join([token.lemma_ if token.lemma_ != \"-PRON-\" else token.text for token in x]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['extract_str'] = d.apply(lambda row: str(row['extract']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "      <th>extract_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>10.0</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>9.2</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date            source  score  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017  Verizon Wireless   10.0   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017       Phone Arena   10.0   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017            Amazon    6.0   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017           Samsung    9.2   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017  Verizon Wireless    4.0   \n",
       "\n",
       "                                             extract    brand  models  \\\n",
       "0  as a diehard samsung fan who has had every sam...  samsung  galaxy   \n",
       "1  love the phone. the phone is sleek and smooth ...  samsung  galaxy   \n",
       "2  adequate feel. nice heft. processor's still sl...  samsung  galaxy   \n",
       "3  never disappointed. one of the reasons i've be...  samsung  galaxy   \n",
       "4  i've now found that i'm in a group of people t...  samsung  galaxy   \n",
       "\n",
       "                                         extract_str  \n",
       "0  as a diehard samsung fan who has had every sam...  \n",
       "1  love the phone. the phone is sleek and smooth ...  \n",
       "2  adequate feel. nice heft. processor's still sl...  \n",
       "3  never disappointed. one of the reasons i've be...  \n",
       "4  i've now found that i'm in a group of people t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "d_lemma = token_lemma(d, 'extract_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "      <th>extract_str</th>\n",
       "      <th>token</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>(as, a, diehard, samsung, fan, who, has, had, ...</td>\n",
       "      <td>as a diehard samsung fan who have have every s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>10.0</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>(love, the, phone, ., the, phone, is, sleek, a...</td>\n",
       "      <td>love the phone . the phone be sleek and smooth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>(adequate, feel, ., nice, heft, ., processor, ...</td>\n",
       "      <td>adequate feel . nice heft . processor 's still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>9.2</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>(never, disappointed, ., one, of, the, reasons...</td>\n",
       "      <td>never disappoint . one of the reason i have be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>(i, 've, now, found, that, i, 'm, in, a, group...</td>\n",
       "      <td>i have now find that i be in a group of people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/10/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>i am the type of person who never would comple...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>i am the type of person who never would comple...</td>\n",
       "      <td>(i, am, the, type, of, person, who, never, wou...</td>\n",
       "      <td>i be the type of person who never would comple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/10/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>the way this samsung s8 phone operates is more...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>the way this samsung s8 phone operates is more...</td>\n",
       "      <td>(the, way, this, samsung, s8, phone, operates,...</td>\n",
       "      <td>the way this samsung s8 phone operate be more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/10/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>6.0</td>\n",
       "      <td>i bought this phone very excited to use it. i ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>i bought this phone very excited to use it. i ...</td>\n",
       "      <td>(i, bought, this, phone, very, excited, to, us...</td>\n",
       "      <td>i buy this phone very excited to use it . i ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/10/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>6.0</td>\n",
       "      <td>it is an extremely advanced and truly a smart ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>it is an extremely advanced and truly a smart ...</td>\n",
       "      <td>(it, is, an, extremely, advanced, and, truly, ...</td>\n",
       "      <td>it be an extremely advanced and truly a smart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/10/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>8.0</td>\n",
       "      <td>great phone with a phenomenal camera, not all ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>great phone with a phenomenal camera, not all ...</td>\n",
       "      <td>(great, phone, with, a, phenomenal, camera, ,,...</td>\n",
       "      <td>great phone with a phenomenal camera , not all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date            source  score  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017  Verizon Wireless   10.0   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017       Phone Arena   10.0   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017            Amazon    6.0   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017           Samsung    9.2   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017  Verizon Wireless    4.0   \n",
       "5  /cellphones/samsung-galaxy-s8/  5/10/2017  Verizon Wireless   10.0   \n",
       "6  /cellphones/samsung-galaxy-s8/  5/10/2017  Verizon Wireless    4.0   \n",
       "7  /cellphones/samsung-galaxy-s8/  5/10/2017  Verizon Wireless    6.0   \n",
       "8  /cellphones/samsung-galaxy-s8/  5/10/2017  Verizon Wireless    6.0   \n",
       "9  /cellphones/samsung-galaxy-s8/  5/10/2017  Verizon Wireless    8.0   \n",
       "\n",
       "                                             extract    brand  models  \\\n",
       "0  as a diehard samsung fan who has had every sam...  samsung  galaxy   \n",
       "1  love the phone. the phone is sleek and smooth ...  samsung  galaxy   \n",
       "2  adequate feel. nice heft. processor's still sl...  samsung  galaxy   \n",
       "3  never disappointed. one of the reasons i've be...  samsung  galaxy   \n",
       "4  i've now found that i'm in a group of people t...  samsung  galaxy   \n",
       "5  i am the type of person who never would comple...  samsung  galaxy   \n",
       "6  the way this samsung s8 phone operates is more...  samsung  galaxy   \n",
       "7  i bought this phone very excited to use it. i ...  samsung  galaxy   \n",
       "8  it is an extremely advanced and truly a smart ...  samsung  galaxy   \n",
       "9  great phone with a phenomenal camera, not all ...  samsung  galaxy   \n",
       "\n",
       "                                         extract_str  \\\n",
       "0  as a diehard samsung fan who has had every sam...   \n",
       "1  love the phone. the phone is sleek and smooth ...   \n",
       "2  adequate feel. nice heft. processor's still sl...   \n",
       "3  never disappointed. one of the reasons i've be...   \n",
       "4  i've now found that i'm in a group of people t...   \n",
       "5  i am the type of person who never would comple...   \n",
       "6  the way this samsung s8 phone operates is more...   \n",
       "7  i bought this phone very excited to use it. i ...   \n",
       "8  it is an extremely advanced and truly a smart ...   \n",
       "9  great phone with a phenomenal camera, not all ...   \n",
       "\n",
       "                                               token  \\\n",
       "0  (as, a, diehard, samsung, fan, who, has, had, ...   \n",
       "1  (love, the, phone, ., the, phone, is, sleek, a...   \n",
       "2  (adequate, feel, ., nice, heft, ., processor, ...   \n",
       "3  (never, disappointed, ., one, of, the, reasons...   \n",
       "4  (i, 've, now, found, that, i, 'm, in, a, group...   \n",
       "5  (i, am, the, type, of, person, who, never, wou...   \n",
       "6  (the, way, this, samsung, s8, phone, operates,...   \n",
       "7  (i, bought, this, phone, very, excited, to, us...   \n",
       "8  (it, is, an, extremely, advanced, and, truly, ...   \n",
       "9  (great, phone, with, a, phenomenal, camera, ,,...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  as a diehard samsung fan who have have every s...  \n",
       "1  love the phone . the phone be sleek and smooth...  \n",
       "2  adequate feel . nice heft . processor 's still...  \n",
       "3  never disappoint . one of the reason i have be...  \n",
       "4  i have now find that i be in a group of people...  \n",
       "5  i be the type of person who never would comple...  \n",
       "6  the way this samsung s8 phone operate be more ...  \n",
       "7  i buy this phone very excited to use it . i ag...  \n",
       "8  it be an extremely advanced and truly a smart ...  \n",
       "9  great phone with a phenomenal camera , not all...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_lemma.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization\n",
    "stopwords2 = stopwords.words() + ['phone', 'phones', 'cell', 'mobile']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2, 3),\n",
    "                             token_pattern = r'\\b[a-zA-Z]{3,}\\b', # detect text with three or more alphanumeric words\n",
    "                             max_df = 0.4,\n",
    "                             min_df = 2,\n",
    "                             stop_words = stopwords2,\n",
    "                             max_features = 200 # keep top 200 features\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_lemma2 = d_lemma.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'printr', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# vectorization\n",
    "corpus = list(d_lemma2[\"lemmatized\"].values)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "features = X.toarray()\n",
    "d_formodel=pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "d_formodel['TARGET'] = d_lemma2['score']  # adding target to the data frame\n",
    "d_formodel.index = d_lemma2['extract'] # adding review to the data frame for future review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection and modeling - LASSO\n",
    "\n",
    "# split train, test sets\n",
    "train_df, test_df = train_test_split(d_formodel)\n",
    "\n",
    "X_train = train_df.loc[:, ~train_df.columns.isin(['TARGET'])] # remove target\n",
    "X_test = test_df.loc[:, ~test_df.columns.isin(['TARGET'])]\n",
    "\n",
    "y_train = train_df['TARGET'] # get target\n",
    "y_test = test_df['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.682604457456658"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline (mean)\n",
    "np.mean(d['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.162747676810994"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline train RMSE\n",
    "baseline_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "baseline_rmse_train['predict'] = np.mean(d['score'])\n",
    "baseline_rmse_train['rmse'] = (baseline_rmse_train['TARGET'] - baseline_rmse_train['predict']) ** 2\n",
    "(sum(baseline_rmse_train['rmse'])/ len(baseline_rmse_train)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "round(r2_score(y_true = baseline_rmse_train['TARGET'], y_pred = baseline_rmse_train['predict']), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.174465773844156"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline test RMSE\n",
    "baseline_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "baseline_rmse_test['predict'] = np.mean(d['score'])\n",
    "baseline_rmse_test['rmse'] = (baseline_rmse_test['TARGET'] - baseline_rmse_test['predict']) ** 2\n",
    "(sum(baseline_rmse_test['rmse'])/ len(baseline_rmse_test)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "round(r2_score(y_true = baseline_rmse_test['TARGET'], y_pred = baseline_rmse_test['predict']), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression \n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "coef_lr = pd.Series(lr.coef_, index = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.569599218690756"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for train set\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "linear_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "linear_rmse_train['predict'] = y_pred\n",
    "linear_rmse_train['rmse'] = (linear_rmse_train['TARGET'] - linear_rmse_train['predict']) ** 2\n",
    "(sum(linear_rmse_train['rmse'])/ len(linear_rmse_train)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.142489589451418"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_score(y_true = linear_rmse_train['TARGET'], y_pred = linear_rmse_train['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5835735973119425"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "linear_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "linear_rmse_test['predict'] = y_pred\n",
    "linear_rmse_test['rmse'] = (linear_rmse_test['TARGET'] - linear_rmse_test['predict']) ** 2\n",
    "(sum(linear_rmse_test['rmse'])/ len(linear_rmse_test)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14154863167969656"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set R2\n",
    "r2_score(y_true = linear_rmse_test['TARGET'], y_pred = linear_rmse_test['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression with alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso picked 35 variables and eliminated the other 165 variables\n"
     ]
    }
   ],
   "source": [
    "# LASSO model with alpha = 0.005\n",
    "# fit model to train\n",
    "reg = Lasso(alpha = 0.005) \n",
    "reg.fit(X_train, y_train)\n",
    "coef_lasso = pd.Series(reg.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef_lasso != 0)) + \" variables and eliminated the other \" +  str(sum(coef_lasso == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.838993267543084"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for train set\n",
    "y_pred = reg.predict(X_train)\n",
    "\n",
    "lasso_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "lasso_rmse_train['predict'] = y_pred\n",
    "lasso_rmse_train['rmse'] = (lasso_rmse_train['TARGET'] - lasso_rmse_train['predict']) ** 2\n",
    "(sum(lasso_rmse_train['rmse'])/ len(lasso_rmse_train)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07777414458753695"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_score(y_true = lasso_rmse_train['TARGET'], y_pred = lasso_rmse_train['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.848641332587018"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for test set\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "lasso_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "lasso_rmse_test['predict'] = y_pred\n",
    "lasso_rmse_test['rmse'] = (lasso_rmse_test['TARGET'] - lasso_rmse_test['predict']) ** 2\n",
    "(sum(lasso_rmse_test['rmse'])/ len(lasso_rmse_test)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07805118873151573"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set R2\n",
    "r2_score(y_true = lasso_rmse_test['TARGET'], y_pred = lasso_rmse_test['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression Cross Validation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso picked 199 variables and eliminated the other 1 variables\n"
     ]
    }
   ],
   "source": [
    "# LASSO CV model\n",
    "# fit model to train\n",
    "reg_cv = LassoCV()\n",
    "reg_cv.fit(X_train, y_train)\n",
    "coef_regcv = pd.Series(reg_cv.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef_regcv != 0)) + \" variables and eliminated the other \" +  str(sum(coef_regcv == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5696333798957722"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for train set\n",
    "y_pred = reg_cv.predict(X_train)\n",
    "\n",
    "lassocv_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "lassocv_rmse_train['predict'] = y_pred\n",
    "lassocv_rmse_train['rmse'] = (lassocv_rmse_train['TARGET'] - lassocv_rmse_train['predict']) ** 2\n",
    "(sum(lassocv_rmse_train['rmse'])/ len(lassocv_rmse_train)) ** 1/2   # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14248138304452773"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_score(y_true = lassocv_rmse_train['TARGET'], y_pred = lassocv_rmse_train['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5836121207615004"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for test set\n",
    "y_pred = reg_cv.predict(X_test)\n",
    "\n",
    "lassocv_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "lassocv_rmse_test['predict'] = y_pred\n",
    "lassocv_rmse_test['rmse'] = (lassocv_rmse_test['TARGET'] - lassocv_rmse_test['predict']) ** 2\n",
    "(sum(lassocv_rmse_test['rmse'])/ len(lassocv_rmse_test)) ** 1/2   # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14153940331862858"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_score(y_true = lassocv_rmse_test['TARGET'], y_pred = lassocv_rmse_test['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients of Best Model (LASSO CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent product    2.452621\n",
       "good ever            2.322421\n",
       "highly recommend     2.229287\n",
       "love new             2.177848\n",
       "great product        2.101927\n",
       "absolutely love      2.079232\n",
       "super fast           2.059029\n",
       "love love            2.032607\n",
       "everything need      2.003075\n",
       "work perfectly       1.963291\n",
       "good iphone          1.957857\n",
       "good smartphone      1.929496\n",
       "great love           1.905807\n",
       "great price          1.830238\n",
       "happy purchase       1.809032\n",
       "great buy            1.799091\n",
       "love everything      1.791737\n",
       "easy use             1.779209\n",
       "love samsung         1.747154\n",
       "nice product         1.734897\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_lr_desc = coef_lr.sort_values(ascending = False)\n",
    "coef_lr_desc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad ever          -5.547389\n",
       "waste money       -4.918649\n",
       "stop work         -4.070216\n",
       "send back         -3.849688\n",
       "work properly     -3.470201\n",
       "buy product       -2.738116\n",
       "hold charge       -2.624118\n",
       "battery drain     -2.263830\n",
       "every time        -2.211277\n",
       "drop call         -2.186340\n",
       "two month         -2.013661\n",
       "one month         -1.833336\n",
       "heating problem   -1.769162\n",
       "month use         -1.704547\n",
       "could get         -1.514371\n",
       "buy new           -1.499779\n",
       "one day           -1.346494\n",
       "make call         -1.315271\n",
       "text message      -1.309045\n",
       "sim card          -1.205412\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_lr_aesc = coef_lr.sort_values(ascending = True)\n",
    "coef_lr_aesc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad ever          -5.540219\n",
       "waste money       -4.914819\n",
       "stop work         -4.069542\n",
       "send back         -3.844052\n",
       "work properly     -3.465388\n",
       "buy product       -2.724912\n",
       "hold charge       -2.612965\n",
       "battery drain     -2.255692\n",
       "every time        -2.198401\n",
       "drop call         -2.175698\n",
       "two month         -1.999704\n",
       "one month         -1.818212\n",
       "heating problem   -1.762694\n",
       "month use         -1.693828\n",
       "could get         -1.501411\n",
       "buy new           -1.489918\n",
       "one day           -1.332836\n",
       "make call         -1.310990\n",
       "text message      -1.300037\n",
       "sim card          -1.204872\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most negative mentioned\n",
    "coef_regcv_asc = coef_regcv.sort_values()\n",
    "coef_regcv_asc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent product    2.443020\n",
       "good ever            2.319211\n",
       "highly recommend     2.221265\n",
       "love new             2.166652\n",
       "great product        2.092117\n",
       "absolutely love      2.069935\n",
       "super fast           2.044935\n",
       "love love            2.014252\n",
       "everything need      1.992939\n",
       "work perfectly       1.955589\n",
       "good iphone          1.941756\n",
       "good smartphone      1.918018\n",
       "great love           1.892222\n",
       "great price          1.825087\n",
       "happy purchase       1.792988\n",
       "great buy            1.780546\n",
       "easy use             1.777148\n",
       "love everything      1.776799\n",
       "love samsung         1.729998\n",
       "nice product         1.719287\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most positive mentioned\n",
    "coef_regcv_desc = coef_regcv.sort_values(ascending = False)\n",
    "coef_regcv_desc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Real Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'printr', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# test reviews data processing\n",
    "test = pd.read_excel('test_review.xlsx', sheet_name = 'Sheet1')\n",
    "test['review'] = test.apply(lambda row: str(row['review']).lower(),axis=1)\n",
    "test['review_str'] = test.apply(lambda row: str(row['review']),axis=1)\n",
    "\n",
    "test_lemma = token_lemma(test, 'review_str')\n",
    "\n",
    "stopwords2 = stopwords.words() + ['phone', 'phones', 'cell', 'mobile']\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2, 3),\n",
    "                             token_pattern = r'\\b[a-zA-Z]{3,}\\b', # detect text with three or more alphanumeric words\n",
    "                             stop_words = stopwords2,\n",
    "                             max_features = 200 # keep top 200 features\n",
    "                            )\n",
    "\n",
    "test_lemma2 = test_lemma.reset_index(drop = True)\n",
    "\n",
    "# vectorization\n",
    "corpus = list(test_lemma2[\"lemmatized\"].values)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "features = X.toarray()\n",
    "test_formodel=pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "test_formodel['TARGET'] = test_lemma2['rating']  # adding target to the data frame\n",
    "test_formodel.index = test_lemma2['review'] # adding review to the data frame for future review\n",
    "\n",
    "testset = test_formodel.loc[:, ~test_formodel.columns.isin(['TARGET'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.69569407,  9.06505434,  8.26465512, 10.96202519,  8.63618571,\n",
       "        9.08661408,  8.32710799,  9.06698603,  6.91532315,  7.84028028,\n",
       "        6.68897733,  8.69979071,  9.29402914])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = reg_cv.predict(testset)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.63618571, 6.68897733])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict select reivews scores\n",
    "review1 = pd.DataFrame(testset.iloc[4,]).T\n",
    "review2 = pd.DataFrame(testset.iloc[10,]).T\n",
    "testset = review1.append(review2)\n",
    "test_pred = reg_cv.predict(testset)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
