{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "\n",
    "# read data\n",
    "d = pd.read_csv('df_eng.csv', index_col = 0)\n",
    "product = list(d['phone_url'].str.split('/'))\n",
    "\n",
    "\n",
    "# parse brand and model from phont_url and add back to the dataframe\n",
    "product2 = []\n",
    "for i in product:\n",
    "    product2.append(i[2])\n",
    "    \n",
    "product2_split = []\n",
    "for p in product2:\n",
    "    product2_split.append(p.split('-'))\n",
    "\n",
    "brands = []\n",
    "for p in product2_split:\n",
    "    brands.append(p[0])\n",
    "    \n",
    "d['brand'] = brands\n",
    "\n",
    "models = []\n",
    "for p in product2_split:\n",
    "    models.append(p[1])\n",
    "    \n",
    "d['models'] = models\n",
    "\n",
    "\n",
    "# delete unused column\n",
    "del d['lang']\n",
    "del d['country']\n",
    "del d['domain']\n",
    "del d['score_max']\n",
    "del d['author']\n",
    "del d['product']\n",
    "\n",
    "\n",
    "# drop columns with nan score\n",
    "d.dropna(subset=['score'], inplace = True)\n",
    "d.dropna(subset = ['extract'], inplace = True)\n",
    "\n",
    "# lowercase extract text\n",
    "d['extract'] = d.apply(lambda row: str(row['extract']).lower(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>10.0</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>9.2</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date            source  score  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017  Verizon Wireless   10.0   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017       Phone Arena   10.0   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017            Amazon    6.0   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017           Samsung    9.2   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017  Verizon Wireless    4.0   \n",
       "\n",
       "                                             extract    brand  models  \n",
       "0  as a diehard samsung fan who has had every sam...  samsung  galaxy  \n",
       "1  love the phone. the phone is sleek and smooth ...  samsung  galaxy  \n",
       "2  adequate feel. nice heft. processor's still sl...  samsung  galaxy  \n",
       "3  never disappointed. one of the reasons i've be...  samsung  galaxy  \n",
       "4  i've now found that i'm in a group of people t...  samsung  galaxy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d.to_csv('data_cleaned.csv')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 100,000 data\n",
    "random.seed(1)\n",
    "d_sample = d.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization and lemmatization function\n",
    "def token_lemma(df,col):\n",
    "    # tokenize by spacy\n",
    "    nlp = spacy.load('en')\n",
    "    df['token'] = df[col].apply(lambda x: nlp(x))\n",
    "    # lemmatize by spacy\n",
    "    df['lemmatized'] = df['token'].apply(lambda x: \" \".join([token.lemma_ for token in x]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['extract_str'] = d.apply(lambda row: str(row['extract']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "      <th>extract_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>10.0</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>9.2</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date            source  score  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017  Verizon Wireless   10.0   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017       Phone Arena   10.0   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017            Amazon    6.0   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017           Samsung    9.2   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017  Verizon Wireless    4.0   \n",
       "\n",
       "                                             extract    brand  models  \\\n",
       "0  as a diehard samsung fan who has had every sam...  samsung  galaxy   \n",
       "1  love the phone. the phone is sleek and smooth ...  samsung  galaxy   \n",
       "2  adequate feel. nice heft. processor's still sl...  samsung  galaxy   \n",
       "3  never disappointed. one of the reasons i've be...  samsung  galaxy   \n",
       "4  i've now found that i'm in a group of people t...  samsung  galaxy   \n",
       "\n",
       "                                         extract_str  \n",
       "0  as a diehard samsung fan who has had every sam...  \n",
       "1  love the phone. the phone is sleek and smooth ...  \n",
       "2  adequate feel. nice heft. processor's still sl...  \n",
       "3  never disappointed. one of the reasons i've be...  \n",
       "4  i've now found that i'm in a group of people t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "d_lemma = token_lemma(d, 'extract_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>extract</th>\n",
       "      <th>brand</th>\n",
       "      <th>models</th>\n",
       "      <th>extract_str</th>\n",
       "      <th>token</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>10.0</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>as a diehard samsung fan who has had every sam...</td>\n",
       "      <td>(as, a, diehard, samsung, fan, who, has, had, ...</td>\n",
       "      <td>as a diehard samsung fan who have have every s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>10.0</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>(love, the, phone, ., the, phone, is, sleek, a...</td>\n",
       "      <td>love the phone . the phone be sleek and smooth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>adequate feel. nice heft. processor's still sl...</td>\n",
       "      <td>(adequate, feel, ., nice, heft, ., processor, ...</td>\n",
       "      <td>adequate feel . nice heft . processor 's still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>9.2</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>never disappointed. one of the reasons i've be...</td>\n",
       "      <td>(never, disappointed, ., one, of, the, reasons...</td>\n",
       "      <td>never disappoint . one of the reason -PRON- ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>i've now found that i'm in a group of people t...</td>\n",
       "      <td>(i, 've, now, found, that, i, 'm, in, a, group...</td>\n",
       "      <td>-PRON- have now find that -PRON- be in a group...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date            source  score  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017  Verizon Wireless   10.0   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017       Phone Arena   10.0   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017            Amazon    6.0   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017           Samsung    9.2   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017  Verizon Wireless    4.0   \n",
       "\n",
       "                                             extract    brand  models  \\\n",
       "0  as a diehard samsung fan who has had every sam...  samsung  galaxy   \n",
       "1  love the phone. the phone is sleek and smooth ...  samsung  galaxy   \n",
       "2  adequate feel. nice heft. processor's still sl...  samsung  galaxy   \n",
       "3  never disappointed. one of the reasons i've be...  samsung  galaxy   \n",
       "4  i've now found that i'm in a group of people t...  samsung  galaxy   \n",
       "\n",
       "                                         extract_str  \\\n",
       "0  as a diehard samsung fan who has had every sam...   \n",
       "1  love the phone. the phone is sleek and smooth ...   \n",
       "2  adequate feel. nice heft. processor's still sl...   \n",
       "3  never disappointed. one of the reasons i've be...   \n",
       "4  i've now found that i'm in a group of people t...   \n",
       "\n",
       "                                               token  \\\n",
       "0  (as, a, diehard, samsung, fan, who, has, had, ...   \n",
       "1  (love, the, phone, ., the, phone, is, sleek, a...   \n",
       "2  (adequate, feel, ., nice, heft, ., processor, ...   \n",
       "3  (never, disappointed, ., one, of, the, reasons...   \n",
       "4  (i, 've, now, found, that, i, 'm, in, a, group...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  as a diehard samsung fan who have have every s...  \n",
       "1  love the phone . the phone be sleek and smooth...  \n",
       "2  adequate feel . nice heft . processor 's still...  \n",
       "3  never disappoint . one of the reason -PRON- ha...  \n",
       "4  -PRON- have now find that -PRON- be in a group...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_lemma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization\n",
    "stopwords2 = stopwords.words() + ['phone', 'phones', 'cell', 'mobile'] # + brand ?\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2,4),\n",
    "                             token_pattern = r'\\b[a-zA-Z]{3,}\\b', # detect text with three or more alphanumeric words\n",
    "                             max_df = 0.4,\n",
    "                             min_df = 2,\n",
    "                             stop_words = stopwords2,\n",
    "                             max_features = 200 # keep top 200 features\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_lemma2 = d_lemma.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'printr', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# vectorization\n",
    "corpus = list(d_lemma2[\"lemmatized\"].values)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "features = X.toarray()\n",
    "d_formodel=pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "d_formodel['TARGET'] = d_lemma2['score']  # adding target to the data frame\n",
    "d_formodel.index = d_lemma2['extract'] # adding review to the data frame for future review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection and modeling - LASSO\n",
    "\n",
    "# split train, test sets\n",
    "train_df, test_df = train_test_split(d_formodel)\n",
    "\n",
    "X_train = train_df.loc[:, ~train_df.columns.isin(['TARGET'])] # remove target\n",
    "X_test = test_df.loc[:, ~test_df.columns.isin(['TARGET'])]\n",
    "\n",
    "y_train = train_df['TARGET'] # get target\n",
    "y_test = test_df['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.669917999999874"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline (mean)\n",
    "np.mean(d['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.158199320608871"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline train RMSE\n",
    "baseline_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "baseline_rmse_train['predict'] = np.mean(d['score'])\n",
    "baseline_rmse_train['rmse'] = (baseline_rmse_train['TARGET'] - baseline_rmse_train['predict']) ** 2\n",
    "(sum(baseline_rmse_train['rmse'])/ len(baseline_rmse_train)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "round(r2_score(y_true = baseline_rmse_train['TARGET'], y_pred = baseline_rmse_train['predict']), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.188432703802451"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline test RMSE\n",
    "baseline_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "baseline_rmse_test['predict'] = np.mean(d['score'])\n",
    "baseline_rmse_test['rmse'] = (baseline_rmse_test['TARGET'] - baseline_rmse_test['predict']) ** 2\n",
    "(sum(baseline_rmse_test['rmse'])/ len(baseline_rmse_test)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "round(r2_score(y_true = baseline_rmse_test['TARGET'], y_pred = baseline_rmse_test['predict']), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression with alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso picked 53 variables and eliminated the other 147 variables\n"
     ]
    }
   ],
   "source": [
    "# LASSO model with alpha = 0.005\n",
    "# fit model to train\n",
    "reg = Lasso(alpha = 0.005) \n",
    "reg.fit(X_train, y_train)\n",
    "coef_lasso = pd.Series(reg.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef_lasso != 0)) + \" variables and eliminated the other \" +  str(sum(coef_lasso == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.734858131351764"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for train set\n",
    "y_pred = reg.predict(X_train)\n",
    "\n",
    "lasso_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "lasso_rmse_train['predict'] = y_pred\n",
    "lasso_rmse_train['rmse'] = (lasso_rmse_train['TARGET'] - lasso_rmse_train['predict']) ** 2\n",
    "(sum(lasso_rmse_train['rmse'])/ len(lasso_rmse_train)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1017798073549726"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_score(y_true = lasso_rmse_train['TARGET'], y_pred = lasso_rmse_train['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.77359440716561"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for test set\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "lasso_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "lasso_rmse_test['predict'] = y_pred\n",
    "lasso_rmse_test['rmse'] = (lasso_rmse_test['TARGET'] - lasso_rmse_test['predict']) ** 2\n",
    "(sum(lasso_rmse_test['rmse'])/ len(lasso_rmse_test)) ** 1/2   #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09904352153064644"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set R2\n",
    "r2_score(y_true = lasso_rmse_test['TARGET'], y_pred = lasso_rmse_test['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression Cross Validation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso picked 200 variables and eliminated the other 0 variables\n"
     ]
    }
   ],
   "source": [
    "# LASSO CV model\n",
    "# fit model to train\n",
    "reg_cv = LassoCV()\n",
    "reg_cv.fit(X_train, y_train)\n",
    "coef_regcv = pd.Series(reg_cv.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef_regcv != 0)) + \" variables and eliminated the other \" +  str(sum(coef_regcv == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.468533592005176"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for train set\n",
    "y_pred = reg_cv.predict(X_train)\n",
    "\n",
    "lassocv_rmse_train = pd.DataFrame(train_df['TARGET'])\n",
    "lassocv_rmse_train['predict'] = y_pred\n",
    "lassocv_rmse_train['rmse'] = (lassocv_rmse_train['TARGET'] - lassocv_rmse_train['predict']) ** 2\n",
    "(sum(lassocv_rmse_train['rmse'])/ len(lassocv_rmse_train)) ** 1/2   # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16582991866226826"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_score(y_true = lassocv_rmse_train['TARGET'], y_pred = lassocv_rmse_train['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.502554629022282"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict for test set\n",
    "y_pred = reg_cv.predict(X_test)\n",
    "\n",
    "lassocv_rmse_test = pd.DataFrame(test_df['TARGET'])\n",
    "lassocv_rmse_test['predict'] = y_pred\n",
    "lassocv_rmse_test['rmse'] = (lassocv_rmse_test['TARGET'] - lassocv_rmse_test['predict']) ** 2\n",
    "(sum(lassocv_rmse_test['rmse'])/ len(lassocv_rmse_test)) ** 1/2   # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16375504526411255"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set R2\n",
    "r2_score(y_true = lassocv_rmse_test['TARGET'], y_pred = lassocv_rmse_test['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients of Best Model (LASSO CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "love pron            2.571221\n",
       "excellent product    2.517053\n",
       "good ever            2.449651\n",
       "work perfectly       2.338617\n",
       "highly recommend     2.310389\n",
       "pron amazing         2.246708\n",
       "pron love            2.201105\n",
       "great product        2.149057\n",
       "pron awesome         2.127979\n",
       "thank pron           2.050783\n",
       "work great           2.023977\n",
       "great price          1.999415\n",
       "easy use             1.969306\n",
       "one good             1.873813\n",
       "everything pron      1.818230\n",
       "absolutely love      1.774539\n",
       "far good             1.765647\n",
       "pron fast            1.761508\n",
       "value money          1.655968\n",
       "happy pron           1.648827\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most positive mentioned\n",
    "coef_regcv_desc = coef_regcv.sort_values(ascending = False)\n",
    "coef_regcv_desc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stop work       -4.466626\n",
       "return pron     -4.132220\n",
       "pron money      -3.769776\n",
       "work properly   -3.455021\n",
       "send pron       -3.016243\n",
       "turn pron       -2.867191\n",
       "pron start      -2.331378\n",
       "work pron       -1.902355\n",
       "month pron      -1.899091\n",
       "pron back       -1.853459\n",
       "call pron       -1.783820\n",
       "charge pron     -1.769439\n",
       "pron keep       -1.731743\n",
       "pron charge     -1.671865\n",
       "pron even       -1.509526\n",
       "tell pron       -1.354031\n",
       "make call       -1.348034\n",
       "sim card        -1.274817\n",
       "time pron       -1.210502\n",
       "back pron       -1.206784\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most negative mentioned\n",
    "coef_regcv_asc = coef_regcv.sort_values()\n",
    "coef_regcv_asc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
